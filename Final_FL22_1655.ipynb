{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2d514ca",
   "metadata": {},
   "source": [
    "# Final Project - PHYS1655 Fall 2022\n",
    "## Classification of Astrophysical Objects (100 points total - 10 points each part)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4afa3e",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "There is an introduction to the project on the course Wiki:\n",
    "https://confluence.its.virginia.edu/display/2P1C/Final+Fall+2022\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c12a32c",
   "metadata": {},
   "source": [
    "## Assignment\n",
    "\n",
    "Ok, now that you understand a little bit about the dataset that we are working with, we can get started!\n",
    "\n",
    "Unless specified otherwise you may use any tool we learned about to accomplish the tasks below.  For example, in part a) you can use a simple readlines() command and then loop over the lines in the file to calculate the requested quantities, or you can use a more advanced tool from Numpy or Pandas if you are aware of one. Use whatever you are most comfortable with to get the job done. \n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346516a2",
   "metadata": {},
   "source": [
    "## a) First Look\n",
    "\n",
    "Write a program that reads in the dataset skyserver.csv, which is in your repository. Calculate the average and standard deviation for each feature and each class. Make a summary table of the following form. Make sure it is human-readable (it doesn't need lines or boxes, but needs reasonable spacing). **Also, how many entries are in this sample? How many of each class are there?**\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "788531b8",
   "metadata": {},
   "source": [
    "| Stars    | avg+-std | ... | ... |  |  |  |\n",
    "| Galaxies | ...      | ... |     |  |  |  |\n",
    "| Quasars  | ...      |     |     |  |  |  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35eaa5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b582e9",
   "metadata": {},
   "source": [
    "Put your narrative here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12e0f32",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5bfd3b",
   "metadata": {},
   "source": [
    "## b) Histograms\n",
    "Make and plot a histogram for the \"r band\" feature. On the same axis, include the distributions for the 3 different classes, drawing each one in a different color, and include a legend. Remember the axis labels and a title!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a6fb041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c540b2",
   "metadata": {},
   "source": [
    "Put your narrative here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f49e83b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e68bc84",
   "metadata": {},
   "source": [
    "## c) Gaussian Fits\n",
    "For the \"r band\" histograms above, fit the three distributions to a Gaussian function and extract the mean and sigma, as well as the uncertainty from the fits. Compare to the values in the first feature column on the table in part a.  **Are they close?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8d95c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0a9316",
   "metadata": {},
   "source": [
    "Put your narrative here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f40fa18",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02c3df9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## d) Plot Fit Results\n",
    "\n",
    "Make three plots, or a single plot with 3 subfigures, and draw the \"r band\" histogram with its best fit Gaussian function. Print the fit values and uncertainties on the figure (title or with a label of some kind)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "115aa86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9201c8",
   "metadata": {},
   "source": [
    "Put your narrative here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57564ac",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b21e436",
   "metadata": {},
   "source": [
    "## e) Fit Quality\n",
    "For the fit for the Galaxy data from part d, assess the quality of the fit. Plot the pull distribution for the residuals (class18 and class19). **Based on the pull distribution, does the Gaussian function describe the data well? Explain how you came to this conclusion. If the pull distribution was perfect, what would it look like? Hint: Use the statisitical uncertainty on each bin of the histogram.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b05d72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b547c250",
   "metadata": {},
   "source": [
    "Put your narrative here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993b9098",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803e537a",
   "metadata": {},
   "source": [
    "## f) Gaussian Classification\n",
    "\n",
    "Based on the best-fit Gaussian functions that you found in part d, assess the discrimination power of classifying the sample based on selecting all of the events within 1-sigma of the Gaussian mean for each class. Try using the filtering methods used in class24.\n",
    "\n",
    "**For each class: Assuming that the underlying distribution is the Gaussian model that you fit for in part d, what would be the fraction that the true class is predicted correctly (i.e. what fraction of the class is within 1-sigma of the mean of the distribution for that class)?**\n",
    "\n",
    "**For each class: What would be the impurity fraction or percentage from each of the other two samples (i.e. what fraction or percentage of incorrect classifications from each of the other two classes would you select with this simple classification)?**\n",
    "\n",
    "This information can be summarized concisely in a [confusion matrix](https://www.w3schools.com/python/python_ml_confusion_matrix.asp)  (we saw this in class24). Construct your own confusion matrix based on this selection and print it to the screen (just the numbers for the fractions are fine). **Provide a short explanation of the false positive and false negative values in the confusion matrix**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3266e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fb1496",
   "metadata": {},
   "source": [
    "Put your narrative here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242b2377",
   "metadata": {},
   "source": [
    "### Bonus (+2)\n",
    "\n",
    "\n",
    "Draw the confusion matrix you constructed in part f) using the Scikit-learn **ConfusionMatrixDisplay** function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b120a141",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put your bonus code here.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf84c72",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4afd66c",
   "metadata": {},
   "source": [
    "## g) Pair Plot\n",
    "Make the \"pair plot\" for the data. **Hint:** We made this in HW09 for the Iris dataset, but we learned a much easier way to do it later in the course (class23)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "387faa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee0a46c",
   "metadata": {},
   "source": [
    "Put your narrative here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42794378",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee61264f",
   "metadata": {},
   "source": [
    "## h) Features for Classification\n",
    "\n",
    "**Based on the pair plot, explain which features might be most useful in classification.**\n",
    "\n",
    "Let's simplify the dataset into just two classes: star v/s galaxy. The Quasar (QSO) is pretty easy to identify, so let's not waste energy on that. Quasars are much farther away than observable stars and galaxies, so they have much higher redshifts. Anyway, use the loc method that we used in class24 notebook (to drop setosa) to remove the Quasars from the dataset.\n",
    "\n",
    "Also, redshift information makes this problem too easy. We don't want that! Remove redshift from the dataset as well. Make the new pair plot. There, that should look much more challenging! \n",
    "\n",
    "I see some outliers in the pair plot. **You don't have to actually do it, but explain what kind of algorithm you might use to remove outliers. Why might it be important to clean up the dataset by removing outliers?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5dbd1c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0203d5",
   "metadata": {},
   "source": [
    "Put your narrative here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641d6e14",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d5bb5b",
   "metadata": {},
   "source": [
    "## i) Training the Neural Network\n",
    "Train a neural network to classify stars and galaxies using the reduced dataset that you made in part h. The question is, how well can you classify star v/s galaxy based on the 5 bands of light data from the SDSS? Play with the hyperparameters a little and see how it affects the accuracy_score to make sure you have a somewhat optimized network. Remember to scale data, since this is crucial in the MLP (class24). **Show the farction of correctly classified samples.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6bf0a508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe6746c",
   "metadata": {},
   "source": [
    "Put your narrative here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f990fc3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671f3daf",
   "metadata": {},
   "source": [
    "## j) Understanding your Neural Network classification performance\n",
    "\n",
    "Plot the Confusion Matrix and **explain what it means**. Make the ROC curve (class24) and **explain what it means**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f58e4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5215b446",
   "metadata": {},
   "source": [
    "Put your narrative here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b791f584",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562eddf5",
   "metadata": {},
   "source": [
    "## Bonus (+5)\n",
    "\n",
    "Awarded to the student(s) who can train the most successful network- that is, find the best set of hyperparameters (as judged by scikit-learn's accuracy_score applied to a random subset of the sample). If you want to compete for these points, you need to include a clearly labeled bonus section of your notebook (or a bonus program username_bonus.py) that loads the dataset and trains the NN with your optimal hyperparameters. There are many ways to optimize your hyperparameters. You may want to write a program to scan through values of hyperparameters and train a NN with each set, recording how it performs, and the parameters you used.  Or, maybe submit a bunch of batch jobs will be necessary? Anyway, it's bonus - do whatever you want - but **make sure to explain what you did**!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f11d7ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonus code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7035f10",
   "metadata": {},
   "source": [
    "Put your bonus narrative here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
